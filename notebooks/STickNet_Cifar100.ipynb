{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "#Add parent directory to path to enable imports\n",
        "# Since we're in notebooks/ directory, go up one level\n",
        "current_dir = os.getcwd()\n",
        "# If we're in notebooks/, go up to parent\n",
        "if current_dir.endswith('notebooks'):\n",
        "    parent_dir = os.path.dirname(current_dir)\n",
        "else:\n",
        "    # If we're already in the root, use current directory\n",
        "    parent_dir = current_dir\n",
        "\n",
        "sys.path.insert(0, parent_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from S_TickNet_Dogs import *\n",
        "from util import get_device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "EPOCH_SIZE = 1\n",
        "BATCH_SIZE = 64\n",
        "GPU_ID = 0\n",
        "BASE_DIR = '../results'\n",
        "DATA_ROOT = '../datasets/Cifar100'\n",
        "CONFIG = 2\n",
        "NETWORK = 'basic'\n",
        "WORKERS = 4\n",
        "LEARNING_RATE = 0.1\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 0.0001\n",
        "SCHEDULE = [100, 150]\n",
        "GAMMA = 0.1\n",
        "DOWNLOAD = True\n",
        "DATASET = 'cifar100'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mps\n"
          ]
        }
      ],
      "source": [
        "device = get_device()\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "THE ACTUAL CHANNEL: basic\n",
            "THE config: [[256], [128], [64], [128, 256], [512]]\n",
            "SpatialTickNet(\n",
            "  (backbone): Sequential(\n",
            "    (data_bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (init_conv): ConvBlock(\n",
            "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (stage1): Sequential(\n",
            "      (unit1): FR_PDP_block(\n",
            "        (Pw1): ConvBlock(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (Dw): ConvBlock(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (Pw2): ConvBlock(\n",
            "          (conv): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (PwR): ConvBlock(\n",
            "          (conv): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (SE): SE(\n",
            "          (ChannelGate): ChannelGate(\n",
            "            (mlp): Sequential(\n",
            "              (0): Flatten()\n",
            "              (1): Linear(in_features=256, out_features=16, bias=True)\n",
            "              (2): ReLU()\n",
            "              (3): Linear(in_features=16, out_features=256, bias=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (stage2): Sequential(\n",
            "      (unit1): FR_PDP_block(\n",
            "        (Pw1): ConvBlock(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (Dw): ConvBlock(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (Pw2): ConvBlock(\n",
            "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (PwR): ConvBlock(\n",
            "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (SE): SE(\n",
            "          (ChannelGate): ChannelGate(\n",
            "            (mlp): Sequential(\n",
            "              (0): Flatten()\n",
            "              (1): Linear(in_features=128, out_features=8, bias=True)\n",
            "              (2): ReLU()\n",
            "              (3): Linear(in_features=8, out_features=128, bias=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (stage3): Sequential(\n",
            "      (unit1): FR_PDP_block(\n",
            "        (Pw1): ConvBlock(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (Dw): ConvBlock(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (Pw2): ConvBlock(\n",
            "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (PwR): ConvBlock(\n",
            "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (SE): SE(\n",
            "          (ChannelGate): ChannelGate(\n",
            "            (mlp): Sequential(\n",
            "              (0): Flatten()\n",
            "              (1): Linear(in_features=64, out_features=4, bias=True)\n",
            "              (2): ReLU()\n",
            "              (3): Linear(in_features=4, out_features=64, bias=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (stage4): Sequential(\n",
            "      (unit1): FR_PDP_block(\n",
            "        (Pw1): ConvBlock(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (Dw): ConvBlock(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (Pw2): ConvBlock(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (PwR): ConvBlock(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (SE): SE(\n",
            "          (ChannelGate): ChannelGate(\n",
            "            (mlp): Sequential(\n",
            "              (0): Flatten()\n",
            "              (1): Linear(in_features=128, out_features=8, bias=True)\n",
            "              (2): ReLU()\n",
            "              (3): Linear(in_features=8, out_features=128, bias=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (unit2): FR_PDP_block(\n",
            "        (Pw1): ConvBlock(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (Dw): ConvBlock(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (Pw2): ConvBlock(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (PwR): ConvBlock(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (SE): SE(\n",
            "          (ChannelGate): ChannelGate(\n",
            "            (mlp): Sequential(\n",
            "              (0): Flatten()\n",
            "              (1): Linear(in_features=256, out_features=16, bias=True)\n",
            "              (2): ReLU()\n",
            "              (3): Linear(in_features=16, out_features=256, bias=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (stage5): Sequential(\n",
            "      (unit1): FR_PDP_block(\n",
            "        (Pw1): ConvBlock(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (Dw): ConvBlock(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (Pw2): ConvBlock(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (PwR): ConvBlock(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (SE): SE(\n",
            "          (ChannelGate): ChannelGate(\n",
            "            (mlp): Sequential(\n",
            "              (0): Flatten()\n",
            "              (1): Linear(in_features=512, out_features=32, bias=True)\n",
            "              (2): ReLU()\n",
            "              (3): Linear(in_features=32, out_features=512, bias=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (final_conv): ConvBlock(\n",
            "      (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (global_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "  )\n",
            "  (classifier): Classifier(\n",
            "    (conv): Conv2d(1024, 120, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            ")\n",
            "Number of model parameters: 1331666\n"
          ]
        }
      ],
      "source": [
        "model = build_STickNet(120, typesize=NETWORK, cifar=True)\n",
        "model = model.to(device)\n",
        "model_params = sum([p.data.nelement() for p in model.parameters()])\n",
        "print(model)\n",
        "print('Number of model parameters: {}'.format(model_params))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        }
      ],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.SGD(\n",
        "        params=model.parameters(),\n",
        "        lr=LEARNING_RATE,\n",
        "        momentum=MOMENTUM,\n",
        "        weight_decay=WEIGHT_DECAY,\n",
        ")\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
        "  optimizer=optimizer, milestones=SCHEDULE, gamma=0.1\n",
        ")\n",
        "\n",
        "# get train and val da  ta loaders\n",
        "train_loader = get_data_loader(\n",
        "    dataset_name=DATASET,\n",
        "    data_root=DATA_ROOT,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    workers=WORKERS,\n",
        "    download=DOWNLOAD,\n",
        "    train=True\n",
        ")\n",
        "val_loader = get_data_loader(\n",
        "    dataset_name=DATASET,\n",
        "    data_root=DATA_ROOT,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    workers=WORKERS,\n",
        "    download=DOWNLOAD,\n",
        "    train=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting epoch 1/1, learning_rate=0.1\n",
            "[train]  epoch 1/1,  batch 1/782,  loss_train=4.93930,  acc_train=0.00%\n",
            "[train]  epoch 1/1,  batch 11/782,  loss_train=4.96085,  acc_train=1.56%\n",
            "[train]  epoch 1/1,  batch 21/782,  loss_train=5.11899,  acc_train=1.56%\n",
            "[train]  epoch 1/1,  batch 31/782,  loss_train=4.90517,  acc_train=3.12%\n",
            "[train]  epoch 1/1,  batch 41/782,  loss_train=4.58996,  acc_train=4.69%\n",
            "[train]  epoch 1/1,  batch 51/782,  loss_train=4.62981,  acc_train=4.69%\n",
            "[train]  epoch 1/1,  batch 61/782,  loss_train=4.36269,  acc_train=6.25%\n",
            "[train]  epoch 1/1,  batch 71/782,  loss_train=4.36639,  acc_train=7.81%\n",
            "[train]  epoch 1/1,  batch 81/782,  loss_train=4.49231,  acc_train=4.69%\n",
            "[train]  epoch 1/1,  batch 91/782,  loss_train=4.26967,  acc_train=7.81%\n",
            "[train]  epoch 1/1,  batch 101/782,  loss_train=4.55717,  acc_train=4.69%\n",
            "[train]  epoch 1/1,  batch 111/782,  loss_train=4.45009,  acc_train=3.12%\n",
            "[train]  epoch 1/1,  batch 121/782,  loss_train=4.39688,  acc_train=7.81%\n",
            "[train]  epoch 1/1,  batch 131/782,  loss_train=4.27815,  acc_train=3.12%\n",
            "[train]  epoch 1/1,  batch 141/782,  loss_train=4.20530,  acc_train=3.12%\n",
            "[train]  epoch 1/1,  batch 151/782,  loss_train=4.38066,  acc_train=3.12%\n",
            "[train]  epoch 1/1,  batch 161/782,  loss_train=4.05035,  acc_train=3.12%\n",
            "[train]  epoch 1/1,  batch 171/782,  loss_train=4.05979,  acc_train=7.81%\n",
            "[train]  epoch 1/1,  batch 181/782,  loss_train=4.33485,  acc_train=3.12%\n",
            "[train]  epoch 1/1,  batch 191/782,  loss_train=4.06756,  acc_train=7.81%\n",
            "[train]  epoch 1/1,  batch 201/782,  loss_train=3.86772,  acc_train=9.38%\n",
            "[train]  epoch 1/1,  batch 211/782,  loss_train=4.09380,  acc_train=3.12%\n",
            "[train]  epoch 1/1,  batch 221/782,  loss_train=4.15482,  acc_train=6.25%\n",
            "[train]  epoch 1/1,  batch 231/782,  loss_train=4.01605,  acc_train=6.25%\n",
            "[train]  epoch 1/1,  batch 241/782,  loss_train=4.13032,  acc_train=4.69%\n",
            "[train]  epoch 1/1,  batch 251/782,  loss_train=4.07409,  acc_train=6.25%\n",
            "[train]  epoch 1/1,  batch 261/782,  loss_train=3.88233,  acc_train=9.38%\n",
            "[train]  epoch 1/1,  batch 271/782,  loss_train=4.16244,  acc_train=6.25%\n",
            "[train]  epoch 1/1,  batch 281/782,  loss_train=4.11882,  acc_train=4.69%\n",
            "[train]  epoch 1/1,  batch 291/782,  loss_train=3.97943,  acc_train=7.81%\n",
            "[train]  epoch 1/1,  batch 301/782,  loss_train=3.86155,  acc_train=12.50%\n",
            "[train]  epoch 1/1,  batch 311/782,  loss_train=3.76489,  acc_train=10.94%\n",
            "[train]  epoch 1/1,  batch 321/782,  loss_train=3.71287,  acc_train=12.50%\n",
            "[train]  epoch 1/1,  batch 331/782,  loss_train=3.81768,  acc_train=10.94%\n",
            "[train]  epoch 1/1,  batch 341/782,  loss_train=4.03166,  acc_train=3.12%\n",
            "[train]  epoch 1/1,  batch 351/782,  loss_train=3.91463,  acc_train=6.25%\n",
            "[train]  epoch 1/1,  batch 361/782,  loss_train=3.86135,  acc_train=6.25%\n",
            "[train]  epoch 1/1,  batch 371/782,  loss_train=3.68053,  acc_train=15.62%\n",
            "[train]  epoch 1/1,  batch 381/782,  loss_train=3.93605,  acc_train=12.50%\n",
            "[train]  epoch 1/1,  batch 391/782,  loss_train=3.82318,  acc_train=10.94%\n",
            "[train]  epoch 1/1,  batch 401/782,  loss_train=3.74328,  acc_train=7.81%\n",
            "[train]  epoch 1/1,  batch 411/782,  loss_train=3.78368,  acc_train=10.94%\n",
            "[train]  epoch 1/1,  batch 421/782,  loss_train=3.60675,  acc_train=12.50%\n",
            "[train]  epoch 1/1,  batch 431/782,  loss_train=3.77771,  acc_train=6.25%\n",
            "[train]  epoch 1/1,  batch 441/782,  loss_train=3.81141,  acc_train=12.50%\n",
            "[train]  epoch 1/1,  batch 451/782,  loss_train=3.74849,  acc_train=10.94%\n",
            "[train]  epoch 1/1,  batch 461/782,  loss_train=3.58468,  acc_train=14.06%\n",
            "[train]  epoch 1/1,  batch 471/782,  loss_train=3.84584,  acc_train=7.81%\n",
            "[train]  epoch 1/1,  batch 481/782,  loss_train=3.49042,  acc_train=23.44%\n",
            "[train]  epoch 1/1,  batch 491/782,  loss_train=3.78597,  acc_train=9.38%\n",
            "[train]  epoch 1/1,  batch 501/782,  loss_train=3.80331,  acc_train=7.81%\n",
            "[train]  epoch 1/1,  batch 511/782,  loss_train=3.30975,  acc_train=15.62%\n",
            "[train]  epoch 1/1,  batch 521/782,  loss_train=3.39318,  acc_train=23.44%\n",
            "[train]  epoch 1/1,  batch 531/782,  loss_train=3.91345,  acc_train=9.38%\n",
            "[train]  epoch 1/1,  batch 541/782,  loss_train=3.59781,  acc_train=9.38%\n",
            "[train]  epoch 1/1,  batch 551/782,  loss_train=3.52553,  acc_train=10.94%\n",
            "[train]  epoch 1/1,  batch 561/782,  loss_train=3.55993,  acc_train=10.94%\n",
            "[train]  epoch 1/1,  batch 571/782,  loss_train=3.36382,  acc_train=20.31%\n",
            "[train]  epoch 1/1,  batch 581/782,  loss_train=3.75772,  acc_train=9.38%\n",
            "[train]  epoch 1/1,  batch 591/782,  loss_train=3.47522,  acc_train=20.31%\n",
            "[train]  epoch 1/1,  batch 601/782,  loss_train=4.01932,  acc_train=10.94%\n",
            "[train]  epoch 1/1,  batch 611/782,  loss_train=3.38773,  acc_train=12.50%\n",
            "[train]  epoch 1/1,  batch 621/782,  loss_train=3.40430,  acc_train=14.06%\n",
            "[train]  epoch 1/1,  batch 631/782,  loss_train=3.69771,  acc_train=9.38%\n",
            "[train]  epoch 1/1,  batch 641/782,  loss_train=3.74313,  acc_train=7.81%\n",
            "[train]  epoch 1/1,  batch 651/782,  loss_train=3.52266,  acc_train=12.50%\n",
            "[train]  epoch 1/1,  batch 661/782,  loss_train=3.39558,  acc_train=20.31%\n",
            "[train]  epoch 1/1,  batch 671/782,  loss_train=3.28133,  acc_train=20.31%\n",
            "[train]  epoch 1/1,  batch 681/782,  loss_train=3.07940,  acc_train=21.88%\n",
            "[train]  epoch 1/1,  batch 691/782,  loss_train=3.31330,  acc_train=17.19%\n",
            "[train]  epoch 1/1,  batch 701/782,  loss_train=3.69811,  acc_train=10.94%\n",
            "[train]  epoch 1/1,  batch 711/782,  loss_train=3.46550,  acc_train=17.19%\n",
            "[train]  epoch 1/1,  batch 721/782,  loss_train=3.15934,  acc_train=21.88%\n",
            "[train]  epoch 1/1,  batch 731/782,  loss_train=3.39711,  acc_train=18.75%\n",
            "[train]  epoch 1/1,  batch 741/782,  loss_train=3.42122,  acc_train=14.06%\n",
            "[train]  epoch 1/1,  batch 751/782,  loss_train=3.23441,  acc_train=17.19%\n",
            "[train]  epoch 1/1,  batch 761/782,  loss_train=3.72285,  acc_train=12.50%\n",
            "[train]  epoch 1/1,  batch 771/782,  loss_train=3.18727,  acc_train=23.44%\n",
            "[train]  epoch 1/1,  batch 781/782,  loss_train=3.77474,  acc_train=12.50%\n",
            "[ val ]  epoch 1/1,  batch 1/157,  loss_val=3.69326,  acc_val=20.31%\n",
            "[ val ]  epoch 1/1,  batch 11/157,  loss_val=3.32673,  acc_val=14.06%\n",
            "[ val ]  epoch 1/1,  batch 21/157,  loss_val=3.50580,  acc_val=25.00%\n",
            "[ val ]  epoch 1/1,  batch 31/157,  loss_val=3.20981,  acc_val=31.25%\n",
            "[ val ]  epoch 1/1,  batch 41/157,  loss_val=3.49888,  acc_val=9.38%\n",
            "[ val ]  epoch 1/1,  batch 51/157,  loss_val=3.43478,  acc_val=14.06%\n",
            "[ val ]  epoch 1/1,  batch 61/157,  loss_val=3.32123,  acc_val=17.19%\n",
            "[ val ]  epoch 1/1,  batch 71/157,  loss_val=3.33421,  acc_val=15.62%\n",
            "[ val ]  epoch 1/1,  batch 81/157,  loss_val=3.54988,  acc_val=17.19%\n",
            "[ val ]  epoch 1/1,  batch 91/157,  loss_val=3.47630,  acc_val=21.88%\n",
            "[ val ]  epoch 1/1,  batch 101/157,  loss_val=3.06390,  acc_val=18.75%\n",
            "[ val ]  epoch 1/1,  batch 111/157,  loss_val=3.50301,  acc_val=15.62%\n",
            "[ val ]  epoch 1/1,  batch 121/157,  loss_val=3.75869,  acc_val=17.19%\n",
            "[ val ]  epoch 1/1,  batch 131/157,  loss_val=3.06513,  acc_val=25.00%\n",
            "[ val ]  epoch 1/1,  batch 141/157,  loss_val=3.20394,  acc_val=17.19%\n",
            "[ val ]  epoch 1/1,  batch 151/157,  loss_val=3.26051,  acc_val=21.88%\n",
            "==================================================================================Epoch 1/1 summary: loss_train=3.85363, acc_train=10.84%, loss_val=3.32, acc_val=19.52% (best: 19.52% @ epoch 1)==================================================================================\n"
          ]
        }
      ],
      "source": [
        "strmode = f'StanfordDogs_S_TickNet_{NETWORK}_SE'\n",
        "pathout = f'{BASE_DIR}/checkpoints/{strmode}'\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(pathout, exist_ok=True)\n",
        "\n",
        "filenameLOG = pathout + '/' + strmode + '.txt'\n",
        "result_file_path = pathout + '/' + strmode + '.csv'\n",
        "val_accuracy_max = None\n",
        "val_accuracy_argmax = None\n",
        "for n_epoch in range(EPOCH_SIZE):\n",
        "    current_learning_rate = optimizer.param_groups[0]['lr']\n",
        "    print(\n",
        "        f'Starting epoch {n_epoch + 1}/{EPOCH_SIZE}, learning_rate={current_learning_rate}'\n",
        "    )\n",
        "    # train\n",
        "    (train_loss, train_accuracy) = run_epoch(\n",
        "        train=True,\n",
        "        data_loader=train_loader,\n",
        "        model=model,\n",
        "        criterion=criterion,\n",
        "        optimizer=optimizer,\n",
        "        n_epoch=n_epoch,\n",
        "        total_epochs=EPOCH_SIZE,\n",
        "        device=device,\n",
        "    )\n",
        "\n",
        "    # validate\n",
        "    (val_loss, val_accuracy) = run_epoch(\n",
        "        train=False,\n",
        "        data_loader=val_loader,\n",
        "        model=model,\n",
        "        criterion=criterion,\n",
        "        optimizer=None,\n",
        "        n_epoch=n_epoch,\n",
        "        total_epochs=EPOCH_SIZE,\n",
        "        device=device,\n",
        "    )\n",
        "    if (val_accuracy_max is None) or (val_accuracy > val_accuracy_max):\n",
        "      val_accuracy_max = val_accuracy\n",
        "      val_accuracy_argmax = n_epoch\n",
        "      torch.save(\n",
        "          {\"model_state_dict\": model.state_dict()},\n",
        "          f'{pathout}/checkpoint_epoch{n_epoch + 1:>04d}_{100.0 * val_accuracy_max:.2f}.pth',\n",
        "      )\n",
        "\n",
        "    # adjust learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "    # print epoch summary\n",
        "    line = (\n",
        "        '=================================================================================='\n",
        "        f'Epoch {n_epoch + 1}/{EPOCH_SIZE} summary: '\n",
        "        f'loss_train={train_loss:.5f}, '\n",
        "        f'acc_train={100.0 * train_accuracy:.2f}%, '\n",
        "        f'loss_val={val_loss:.2f}, '\n",
        "        f'acc_val={100.0 * val_accuracy:.2f}% '\n",
        "        f'(best: {100.0 * val_accuracy_max:.2f}% @ epoch {(val_accuracy_argmax or 0) + 1})'\n",
        "        '=================================================================================='\n",
        "    )\n",
        "    print(line)\n",
        "    wA.writeLogAcc(filenameLOG, line)\n",
        "    wA.log_results_to_csv(\n",
        "        result_file_path,\n",
        "        n_epoch + 1,\n",
        "        train_loss,\n",
        "        100.0 * train_accuracy,\n",
        "        val_loss,\n",
        "        100.0 * val_accuracy,\n",
        "    )\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "jenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
