{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "#Add parent directory to path to enable imports\n",
        "# Since we're in notebooks/ directory, go up one level\n",
        "current_dir = os.getcwd()\n",
        "# If we're in notebooks/, go up to parent\n",
        "if current_dir.endswith('notebooks'):\n",
        "    parent_dir = os.path.dirname(current_dir)\n",
        "else:\n",
        "    # If we're already in the root, use current directory\n",
        "    parent_dir = current_dir\n",
        "\n",
        "sys.path.insert(0, parent_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "from S_TickNet_Dogs import *\n",
        "from util import get_device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "EPOCH_SIZE = 1\n",
        "BATCH_SIZE = 64\n",
        "GPU_ID = 0\n",
        "BASE_DIR = '../results'\n",
        "DATA_ROOT = '../datasets/StanfordDogs'\n",
        "CONFIG = 2\n",
        "NETWORK = 'basic'\n",
        "WORKERS = 4\n",
        "LEARNING_RATE = 0.1\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 0.0001\n",
        "SCHEDULE = [100, 150]\n",
        "GAMMA = 0.1\n",
        "DOWNLOAD = True\n",
        "DATASET = 'dogs'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mps\n"
          ]
        }
      ],
      "source": [
        "device = get_device()\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "THE ACTUAL CHANNEL: basic\n",
            "THE config: [[256], [128], [64], [128, 256], [512]]\n",
            "SpatialTickNet(\n",
            "  (backbone): Sequential(\n",
            "    (data_bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (init_conv): ConvBlock(\n",
            "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (stage1): Sequential(\n",
            "      (unit1): FR_PDP_block(\n",
            "        (Pw1): ConvBlock(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (Dw): ConvBlock(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (Pw2): ConvBlock(\n",
            "          (conv): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (PwR): ConvBlock(\n",
            "          (conv): Conv2d(32, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (SE): SE(\n",
            "          (ChannelGate): ChannelGate(\n",
            "            (mlp): Sequential(\n",
            "              (0): Flatten()\n",
            "              (1): Linear(in_features=256, out_features=16, bias=True)\n",
            "              (2): ReLU()\n",
            "              (3): Linear(in_features=16, out_features=256, bias=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (stage2): Sequential(\n",
            "      (unit1): FR_PDP_block(\n",
            "        (Pw1): ConvBlock(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (Dw): ConvBlock(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (Pw2): ConvBlock(\n",
            "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (PwR): ConvBlock(\n",
            "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (SE): SE(\n",
            "          (ChannelGate): ChannelGate(\n",
            "            (mlp): Sequential(\n",
            "              (0): Flatten()\n",
            "              (1): Linear(in_features=128, out_features=8, bias=True)\n",
            "              (2): ReLU()\n",
            "              (3): Linear(in_features=8, out_features=128, bias=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (stage3): Sequential(\n",
            "      (unit1): FR_PDP_block(\n",
            "        (Pw1): ConvBlock(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (Dw): ConvBlock(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (Pw2): ConvBlock(\n",
            "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (PwR): ConvBlock(\n",
            "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (SE): SE(\n",
            "          (ChannelGate): ChannelGate(\n",
            "            (mlp): Sequential(\n",
            "              (0): Flatten()\n",
            "              (1): Linear(in_features=64, out_features=4, bias=True)\n",
            "              (2): ReLU()\n",
            "              (3): Linear(in_features=4, out_features=64, bias=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (stage4): Sequential(\n",
            "      (unit1): FR_PDP_block(\n",
            "        (Pw1): ConvBlock(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (Dw): ConvBlock(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (Pw2): ConvBlock(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (PwR): ConvBlock(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (SE): SE(\n",
            "          (ChannelGate): ChannelGate(\n",
            "            (mlp): Sequential(\n",
            "              (0): Flatten()\n",
            "              (1): Linear(in_features=128, out_features=8, bias=True)\n",
            "              (2): ReLU()\n",
            "              (3): Linear(in_features=8, out_features=128, bias=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (unit2): FR_PDP_block(\n",
            "        (Pw1): ConvBlock(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (Dw): ConvBlock(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (Pw2): ConvBlock(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (PwR): ConvBlock(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (SE): SE(\n",
            "          (ChannelGate): ChannelGate(\n",
            "            (mlp): Sequential(\n",
            "              (0): Flatten()\n",
            "              (1): Linear(in_features=256, out_features=16, bias=True)\n",
            "              (2): ReLU()\n",
            "              (3): Linear(in_features=16, out_features=256, bias=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (stage5): Sequential(\n",
            "      (unit1): FR_PDP_block(\n",
            "        (Pw1): ConvBlock(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (Dw): ConvBlock(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (Pw2): ConvBlock(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (PwR): ConvBlock(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (SE): SE(\n",
            "          (ChannelGate): ChannelGate(\n",
            "            (mlp): Sequential(\n",
            "              (0): Flatten()\n",
            "              (1): Linear(in_features=512, out_features=32, bias=True)\n",
            "              (2): ReLU()\n",
            "              (3): Linear(in_features=32, out_features=512, bias=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (final_conv): ConvBlock(\n",
            "      (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (global_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "  )\n",
            "  (classifier): Classifier(\n",
            "    (conv): Conv2d(1024, 120, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            ")\n",
            "Number of model parameters: 1331666\n"
          ]
        }
      ],
      "source": [
        "model = build_SpatialTickNet(120, typesize=NETWORK, cifar=False)\n",
        "model = model.to(device)\n",
        "model_params = sum([p.data.nelement() for p in model.parameters()])\n",
        "print(model)\n",
        "print('Number of model parameters: {}'.format(model_params))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File 'images.tar' was already extracted, skipped extraction\n",
            "File 'lists.tar' was already extracted, skipped extraction\n",
            "File 'images.tar' was already extracted, skipped extraction\n",
            "File 'lists.tar' was already extracted, skipped extraction\n"
          ]
        }
      ],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.SGD(\n",
        "        params=model.parameters(),\n",
        "        lr=LEARNING_RATE,\n",
        "        momentum=MOMENTUM,\n",
        "        weight_decay=WEIGHT_DECAY,\n",
        ")\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
        "  optimizer=optimizer, milestones=SCHEDULE, gamma=0.1\n",
        ")\n",
        "\n",
        "# get train and val da  ta loaders\n",
        "train_loader = get_data_loader(\n",
        "    dataset_name=DATASET,\n",
        "    data_root=DATA_ROOT,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    workers=WORKERS,\n",
        "    download=DOWNLOAD,\n",
        "    train=True\n",
        ")\n",
        "val_loader = get_data_loader(\n",
        "    dataset_name=DATASET,\n",
        "    data_root=DATA_ROOT,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    workers=WORKERS,\n",
        "    download=DOWNLOAD,\n",
        "    train=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting epoch 1/1, learning_rate=0.1\n",
            "[train]  epoch 1/1,  batch 1/188,  loss_train=4.96366,  acc_train=3.12%\n",
            "[train]  epoch 1/1,  batch 11/188,  loss_train=5.05612,  acc_train=3.12%\n",
            "[train]  epoch 1/1,  batch 21/188,  loss_train=5.31040,  acc_train=1.56%\n",
            "[train]  epoch 1/1,  batch 31/188,  loss_train=4.88257,  acc_train=7.81%\n",
            "[train]  epoch 1/1,  batch 41/188,  loss_train=4.92913,  acc_train=0.00%\n",
            "[train]  epoch 1/1,  batch 51/188,  loss_train=4.89538,  acc_train=0.00%\n",
            "[train]  epoch 1/1,  batch 61/188,  loss_train=4.89532,  acc_train=0.00%\n",
            "[train]  epoch 1/1,  batch 71/188,  loss_train=4.77572,  acc_train=1.56%\n",
            "[train]  epoch 1/1,  batch 81/188,  loss_train=4.78582,  acc_train=0.00%\n",
            "[train]  epoch 1/1,  batch 91/188,  loss_train=4.70988,  acc_train=1.56%\n",
            "[train]  epoch 1/1,  batch 101/188,  loss_train=4.79405,  acc_train=3.12%\n",
            "[train]  epoch 1/1,  batch 111/188,  loss_train=4.83475,  acc_train=0.00%\n",
            "[train]  epoch 1/1,  batch 121/188,  loss_train=4.77779,  acc_train=0.00%\n",
            "[train]  epoch 1/1,  batch 131/188,  loss_train=4.70762,  acc_train=0.00%\n",
            "[train]  epoch 1/1,  batch 141/188,  loss_train=4.78304,  acc_train=1.56%\n",
            "[train]  epoch 1/1,  batch 151/188,  loss_train=4.71141,  acc_train=3.12%\n",
            "[train]  epoch 1/1,  batch 161/188,  loss_train=4.76345,  acc_train=0.00%\n",
            "[train]  epoch 1/1,  batch 171/188,  loss_train=4.85382,  acc_train=1.56%\n",
            "[train]  epoch 1/1,  batch 181/188,  loss_train=4.72543,  acc_train=1.56%\n",
            "[ val ]  epoch 1/1,  batch 1/135,  loss_val=4.86169,  acc_val=0.00%\n",
            "[ val ]  epoch 1/1,  batch 11/135,  loss_val=5.05209,  acc_val=0.00%\n",
            "[ val ]  epoch 1/1,  batch 21/135,  loss_val=4.32300,  acc_val=0.00%\n",
            "[ val ]  epoch 1/1,  batch 31/135,  loss_val=4.66815,  acc_val=0.00%\n",
            "[ val ]  epoch 1/1,  batch 41/135,  loss_val=4.70531,  acc_val=0.00%\n",
            "[ val ]  epoch 1/1,  batch 51/135,  loss_val=4.70475,  acc_val=9.38%\n",
            "[ val ]  epoch 1/1,  batch 61/135,  loss_val=4.39927,  acc_val=0.00%\n",
            "[ val ]  epoch 1/1,  batch 71/135,  loss_val=4.41004,  acc_val=7.81%\n",
            "[ val ]  epoch 1/1,  batch 81/135,  loss_val=4.84675,  acc_val=0.00%\n",
            "[ val ]  epoch 1/1,  batch 91/135,  loss_val=4.50505,  acc_val=0.00%\n",
            "[ val ]  epoch 1/1,  batch 101/135,  loss_val=4.28134,  acc_val=14.06%\n",
            "[ val ]  epoch 1/1,  batch 111/135,  loss_val=4.55814,  acc_val=0.00%\n",
            "[ val ]  epoch 1/1,  batch 121/135,  loss_val=4.49723,  acc_val=0.00%\n",
            "[ val ]  epoch 1/1,  batch 131/135,  loss_val=4.86467,  acc_val=0.00%\n",
            "==================================================================================Epoch 1/1 summary: loss_train=4.86283, acc_train=1.16%, loss_val=4.71, acc_val=1.52% (best: 1.52% @ epoch 1)==================================================================================\n"
          ]
        }
      ],
      "source": [
        "strmode = f'StanfordDogs_S_TickNet_{NETWORK}_SE'\n",
        "pathout = f'{BASE_DIR}/checkpoints/{strmode}'\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(pathout, exist_ok=True)\n",
        "\n",
        "filenameLOG = pathout + '/' + strmode + '.txt'\n",
        "result_file_path = pathout + '/' + strmode + '.csv'\n",
        "val_accuracy_max = None\n",
        "val_accuracy_argmax = None\n",
        "for n_epoch in range(EPOCH_SIZE):\n",
        "    current_learning_rate = optimizer.param_groups[0]['lr']\n",
        "    print(\n",
        "        f'Starting epoch {n_epoch + 1}/{EPOCH_SIZE}, learning_rate={current_learning_rate}'\n",
        "    )\n",
        "    # train\n",
        "    (train_loss, train_accuracy) = run_epoch(\n",
        "        train=True,\n",
        "        data_loader=train_loader,\n",
        "        model=model,\n",
        "        criterion=criterion,\n",
        "        optimizer=optimizer,\n",
        "        n_epoch=n_epoch,\n",
        "        total_epochs=EPOCH_SIZE,\n",
        "        device=device,\n",
        "    )\n",
        "\n",
        "    # validate\n",
        "    (val_loss, val_accuracy) = run_epoch(\n",
        "        train=False,\n",
        "        data_loader=val_loader,\n",
        "        model=model,\n",
        "        criterion=criterion,\n",
        "        optimizer=None,\n",
        "        n_epoch=n_epoch,\n",
        "        total_epochs=EPOCH_SIZE,\n",
        "        device=device,\n",
        "    )\n",
        "    if (val_accuracy_max is None) or (val_accuracy > val_accuracy_max):\n",
        "      val_accuracy_max = val_accuracy\n",
        "      val_accuracy_argmax = n_epoch\n",
        "      torch.save(\n",
        "          {\"model_state_dict\": model.state_dict()},\n",
        "          f'{pathout}/checkpoint_epoch{n_epoch + 1:>04d}_{100.0 * val_accuracy_max:.2f}.pth',\n",
        "      )\n",
        "\n",
        "    # adjust learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "    # print epoch summary\n",
        "    line = (\n",
        "        '=================================================================================='\n",
        "        f'Epoch {n_epoch + 1}/{EPOCH_SIZE} summary: '\n",
        "        f'loss_train={train_loss:.5f}, '\n",
        "        f'acc_train={100.0 * train_accuracy:.2f}%, '\n",
        "        f'loss_val={val_loss:.2f}, '\n",
        "        f'acc_val={100.0 * val_accuracy:.2f}% '\n",
        "        f'(best: {100.0 * val_accuracy_max:.2f}% @ epoch {(val_accuracy_argmax or 0) + 1})'\n",
        "        '=================================================================================='\n",
        "    )\n",
        "    print(line)\n",
        "    wA.writeLogAcc(filenameLOG, line)\n",
        "    wA.log_results_to_csv(\n",
        "        result_file_path,\n",
        "        n_epoch + 1,\n",
        "        train_loss,\n",
        "        100.0 * train_accuracy,\n",
        "        val_loss,\n",
        "        100.0 * val_accuracy,\n",
        "    )\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "jenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
