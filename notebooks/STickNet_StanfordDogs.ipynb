{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "#Add parent directory to path to enable imports\n",
        "# Since we're in notebooks/ directory, go up one level\n",
        "current_dir = os.getcwd()\n",
        "# If we're in notebooks/, go up to parent\n",
        "if current_dir.endswith('notebooks'):\n",
        "    parent_dir = os.path.dirname(current_dir)\n",
        "else:\n",
        "    # If we're already in the root, use current directory\n",
        "    parent_dir = current_dir\n",
        "\n",
        "sys.path.insert(0, parent_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from S_TickNet_Dogs import *\n",
        "from util import get_device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "EPOCH_SIZE = 1\n",
        "BATCH_SIZE = 64\n",
        "GPU_ID = 0\n",
        "BASE_DIR = '../results'\n",
        "DATA_ROOT = '../datasets/Cifar100'\n",
        "CONFIG = 2\n",
        "NETWORK = 'basic'\n",
        "WORKERS = 4\n",
        "LEARNING_RATE = 0.1\n",
        "MOMENTUM = 0.9\n",
        "WEIGHT_DECAY = 0.0001\n",
        "SCHEDULE = [100, 150]\n",
        "GAMMA = 0.1\n",
        "DOWNLOAD = True\n",
        "DATASET = 'cifar100'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mps\n"
          ]
        }
      ],
      "source": [
        "device = get_device()\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "THE ACTUAL CHANNEL: basic\n",
            "THE config: [[256], [128], [64], [128, 256], [512]]\n",
            "SpatialTickNet(\n",
            "  (backbone): Sequential(\n",
            "    (data_bn): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (init_conv): ConvBlock(\n",
            "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (stage1): Sequential(\n",
            "      (unit1): FR_PDP_block(\n",
            "        (Pw1): ConvBlock(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (Dw): ConvBlock(\n",
            "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (Pw2): ConvBlock(\n",
            "          (conv): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (PwR): ConvBlock(\n",
            "          (conv): Conv2d(32, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (SE): SE(\n",
            "          (ChannelGate): ChannelGate(\n",
            "            (mlp): Sequential(\n",
            "              (0): Flatten()\n",
            "              (1): Linear(in_features=256, out_features=16, bias=True)\n",
            "              (2): ReLU()\n",
            "              (3): Linear(in_features=16, out_features=256, bias=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (stage2): Sequential(\n",
            "      (unit1): FR_PDP_block(\n",
            "        (Pw1): ConvBlock(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (Dw): ConvBlock(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (Pw2): ConvBlock(\n",
            "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (PwR): ConvBlock(\n",
            "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (SE): SE(\n",
            "          (ChannelGate): ChannelGate(\n",
            "            (mlp): Sequential(\n",
            "              (0): Flatten()\n",
            "              (1): Linear(in_features=128, out_features=8, bias=True)\n",
            "              (2): ReLU()\n",
            "              (3): Linear(in_features=8, out_features=128, bias=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (stage3): Sequential(\n",
            "      (unit1): FR_PDP_block(\n",
            "        (Pw1): ConvBlock(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (Dw): ConvBlock(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (Pw2): ConvBlock(\n",
            "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (PwR): ConvBlock(\n",
            "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (SE): SE(\n",
            "          (ChannelGate): ChannelGate(\n",
            "            (mlp): Sequential(\n",
            "              (0): Flatten()\n",
            "              (1): Linear(in_features=64, out_features=4, bias=True)\n",
            "              (2): ReLU()\n",
            "              (3): Linear(in_features=4, out_features=64, bias=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (stage4): Sequential(\n",
            "      (unit1): FR_PDP_block(\n",
            "        (Pw1): ConvBlock(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (Dw): ConvBlock(\n",
            "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
            "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (Pw2): ConvBlock(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (PwR): ConvBlock(\n",
            "          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (SE): SE(\n",
            "          (ChannelGate): ChannelGate(\n",
            "            (mlp): Sequential(\n",
            "              (0): Flatten()\n",
            "              (1): Linear(in_features=128, out_features=8, bias=True)\n",
            "              (2): ReLU()\n",
            "              (3): Linear(in_features=8, out_features=128, bias=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (unit2): FR_PDP_block(\n",
            "        (Pw1): ConvBlock(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (Dw): ConvBlock(\n",
            "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (Pw2): ConvBlock(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (PwR): ConvBlock(\n",
            "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (SE): SE(\n",
            "          (ChannelGate): ChannelGate(\n",
            "            (mlp): Sequential(\n",
            "              (0): Flatten()\n",
            "              (1): Linear(in_features=256, out_features=16, bias=True)\n",
            "              (2): ReLU()\n",
            "              (3): Linear(in_features=16, out_features=256, bias=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (stage5): Sequential(\n",
            "      (unit1): FR_PDP_block(\n",
            "        (Pw1): ConvBlock(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        )\n",
            "        (Dw): ConvBlock(\n",
            "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
            "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (Pw2): ConvBlock(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (PwR): ConvBlock(\n",
            "          (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (activation): ReLU(inplace=True)\n",
            "        )\n",
            "        (SE): SE(\n",
            "          (ChannelGate): ChannelGate(\n",
            "            (mlp): Sequential(\n",
            "              (0): Flatten()\n",
            "              (1): Linear(in_features=512, out_features=32, bias=True)\n",
            "              (2): ReLU()\n",
            "              (3): Linear(in_features=32, out_features=512, bias=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (final_conv): ConvBlock(\n",
            "      (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (activation): ReLU(inplace=True)\n",
            "    )\n",
            "    (global_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "  )\n",
            "  (classifier): Classifier(\n",
            "    (conv): Conv2d(1024, 120, kernel_size=(1, 1), stride=(1, 1))\n",
            "  )\n",
            ")\n",
            "Number of model parameters: 1331666\n"
          ]
        }
      ],
      "source": [
        "model = build_STickNet(120, typesize=NETWORK, cifar=True)\n",
        "model = model.to(device)\n",
        "model_params = sum([p.data.nelement() for p in model.parameters()])\n",
        "print(model)\n",
        "print('Number of model parameters: {}'.format(model_params))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.SGD(\n",
        "        params=model.parameters(),\n",
        "        lr=LEARNING_RATE,\n",
        "        momentum=MOMENTUM,\n",
        "        weight_decay=WEIGHT_DECAY,\n",
        ")\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
        "  optimizer=optimizer, milestones=SCHEDULE, gamma=0.1\n",
        ")\n",
        "\n",
        "# get train and val da  ta loaders\n",
        "train_loader = get_data_loader(\n",
        "    dataset_name=DATASET,\n",
        "    data_root=DATA_ROOT,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    workers=WORKERS,\n",
        "    download=DOWNLOAD,\n",
        "    train=True\n",
        ")\n",
        "val_loader = get_data_loader(\n",
        "    dataset_name=DATASET,\n",
        "    data_root=DATA_ROOT,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    workers=WORKERS,\n",
        "    download=DOWNLOAD,\n",
        "    train=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting epoch 1/1, learning_rate=0.1\n",
            "[train]  epoch 1/1,  batch 1/782,  loss_train=4.94707,  acc_train=1.56%\n",
            "[train]  epoch 1/1,  batch 11/782,  loss_train=4.82665,  acc_train=4.69%\n",
            "[train]  epoch 1/1,  batch 21/782,  loss_train=4.96397,  acc_train=3.12%\n",
            "[train]  epoch 1/1,  batch 31/782,  loss_train=5.07506,  acc_train=0.00%\n",
            "[train]  epoch 1/1,  batch 41/782,  loss_train=4.82221,  acc_train=0.00%\n",
            "[train]  epoch 1/1,  batch 51/782,  loss_train=4.43169,  acc_train=7.81%\n",
            "[train]  epoch 1/1,  batch 61/782,  loss_train=4.79113,  acc_train=1.56%\n",
            "[train]  epoch 1/1,  batch 71/782,  loss_train=4.44360,  acc_train=3.12%\n",
            "[train]  epoch 1/1,  batch 81/782,  loss_train=4.19709,  acc_train=6.25%\n",
            "[train]  epoch 1/1,  batch 91/782,  loss_train=4.56934,  acc_train=3.12%\n",
            "[train]  epoch 1/1,  batch 101/782,  loss_train=4.36267,  acc_train=6.25%\n",
            "[train]  epoch 1/1,  batch 111/782,  loss_train=4.12534,  acc_train=6.25%\n",
            "[train]  epoch 1/1,  batch 121/782,  loss_train=4.12657,  acc_train=9.38%\n",
            "[train]  epoch 1/1,  batch 131/782,  loss_train=4.34298,  acc_train=4.69%\n",
            "[train]  epoch 1/1,  batch 141/782,  loss_train=4.39812,  acc_train=4.69%\n",
            "[train]  epoch 1/1,  batch 151/782,  loss_train=4.05246,  acc_train=6.25%\n",
            "[train]  epoch 1/1,  batch 161/782,  loss_train=3.85111,  acc_train=10.94%\n",
            "[train]  epoch 1/1,  batch 171/782,  loss_train=4.19682,  acc_train=6.25%\n",
            "[train]  epoch 1/1,  batch 181/782,  loss_train=3.96902,  acc_train=12.50%\n",
            "[train]  epoch 1/1,  batch 191/782,  loss_train=3.96907,  acc_train=9.38%\n",
            "[train]  epoch 1/1,  batch 201/782,  loss_train=4.21688,  acc_train=6.25%\n",
            "[train]  epoch 1/1,  batch 211/782,  loss_train=4.02115,  acc_train=3.12%\n",
            "[train]  epoch 1/1,  batch 221/782,  loss_train=3.89896,  acc_train=9.38%\n",
            "[train]  epoch 1/1,  batch 231/782,  loss_train=3.90351,  acc_train=10.94%\n",
            "[train]  epoch 1/1,  batch 241/782,  loss_train=4.01505,  acc_train=7.81%\n",
            "[train]  epoch 1/1,  batch 251/782,  loss_train=3.60260,  acc_train=14.06%\n",
            "[train]  epoch 1/1,  batch 261/782,  loss_train=4.23789,  acc_train=3.12%\n",
            "[train]  epoch 1/1,  batch 271/782,  loss_train=3.66511,  acc_train=7.81%\n",
            "[train]  epoch 1/1,  batch 281/782,  loss_train=4.09896,  acc_train=9.38%\n",
            "[train]  epoch 1/1,  batch 291/782,  loss_train=3.94695,  acc_train=6.25%\n",
            "[train]  epoch 1/1,  batch 301/782,  loss_train=3.93484,  acc_train=3.12%\n",
            "[train]  epoch 1/1,  batch 311/782,  loss_train=3.72981,  acc_train=12.50%\n",
            "[train]  epoch 1/1,  batch 321/782,  loss_train=3.81712,  acc_train=9.38%\n",
            "[train]  epoch 1/1,  batch 331/782,  loss_train=4.19636,  acc_train=9.38%\n",
            "[train]  epoch 1/1,  batch 341/782,  loss_train=3.74527,  acc_train=9.38%\n",
            "[train]  epoch 1/1,  batch 351/782,  loss_train=3.94874,  acc_train=9.38%\n",
            "[train]  epoch 1/1,  batch 361/782,  loss_train=3.57465,  acc_train=15.62%\n",
            "[train]  epoch 1/1,  batch 371/782,  loss_train=3.77535,  acc_train=15.62%\n",
            "[train]  epoch 1/1,  batch 381/782,  loss_train=3.85843,  acc_train=7.81%\n",
            "[train]  epoch 1/1,  batch 391/782,  loss_train=3.92745,  acc_train=4.69%\n",
            "[train]  epoch 1/1,  batch 401/782,  loss_train=3.80320,  acc_train=15.62%\n",
            "[train]  epoch 1/1,  batch 411/782,  loss_train=3.54577,  acc_train=18.75%\n",
            "[train]  epoch 1/1,  batch 421/782,  loss_train=3.83466,  acc_train=10.94%\n",
            "[train]  epoch 1/1,  batch 431/782,  loss_train=3.87491,  acc_train=9.38%\n",
            "[train]  epoch 1/1,  batch 441/782,  loss_train=3.65098,  acc_train=10.94%\n",
            "[train]  epoch 1/1,  batch 451/782,  loss_train=3.88472,  acc_train=9.38%\n",
            "[train]  epoch 1/1,  batch 461/782,  loss_train=4.00808,  acc_train=9.38%\n",
            "[train]  epoch 1/1,  batch 471/782,  loss_train=3.63637,  acc_train=14.06%\n",
            "[train]  epoch 1/1,  batch 481/782,  loss_train=3.63061,  acc_train=9.38%\n",
            "[train]  epoch 1/1,  batch 491/782,  loss_train=3.67278,  acc_train=17.19%\n",
            "[train]  epoch 1/1,  batch 501/782,  loss_train=3.39018,  acc_train=15.62%\n",
            "[train]  epoch 1/1,  batch 511/782,  loss_train=3.47794,  acc_train=14.06%\n",
            "[train]  epoch 1/1,  batch 521/782,  loss_train=3.52941,  acc_train=17.19%\n",
            "[train]  epoch 1/1,  batch 531/782,  loss_train=3.42597,  acc_train=18.75%\n",
            "[train]  epoch 1/1,  batch 541/782,  loss_train=3.83965,  acc_train=12.50%\n",
            "[train]  epoch 1/1,  batch 551/782,  loss_train=3.59180,  acc_train=12.50%\n",
            "[train]  epoch 1/1,  batch 561/782,  loss_train=3.63570,  acc_train=9.38%\n",
            "[train]  epoch 1/1,  batch 571/782,  loss_train=3.47710,  acc_train=17.19%\n",
            "[train]  epoch 1/1,  batch 581/782,  loss_train=3.25700,  acc_train=20.31%\n",
            "[train]  epoch 1/1,  batch 591/782,  loss_train=3.46446,  acc_train=17.19%\n",
            "[train]  epoch 1/1,  batch 601/782,  loss_train=3.18224,  acc_train=28.12%\n",
            "[train]  epoch 1/1,  batch 611/782,  loss_train=3.64532,  acc_train=9.38%\n",
            "[train]  epoch 1/1,  batch 621/782,  loss_train=3.51576,  acc_train=20.31%\n",
            "[train]  epoch 1/1,  batch 631/782,  loss_train=3.47814,  acc_train=14.06%\n",
            "[train]  epoch 1/1,  batch 641/782,  loss_train=2.99758,  acc_train=28.12%\n",
            "[train]  epoch 1/1,  batch 651/782,  loss_train=3.50652,  acc_train=3.12%\n",
            "[train]  epoch 1/1,  batch 661/782,  loss_train=3.30217,  acc_train=17.19%\n",
            "[train]  epoch 1/1,  batch 671/782,  loss_train=3.72687,  acc_train=17.19%\n",
            "[train]  epoch 1/1,  batch 681/782,  loss_train=3.52678,  acc_train=14.06%\n",
            "[train]  epoch 1/1,  batch 691/782,  loss_train=3.35767,  acc_train=14.06%\n",
            "[train]  epoch 1/1,  batch 701/782,  loss_train=3.34889,  acc_train=14.06%\n",
            "[train]  epoch 1/1,  batch 711/782,  loss_train=3.45033,  acc_train=15.62%\n",
            "[train]  epoch 1/1,  batch 721/782,  loss_train=3.18212,  acc_train=21.88%\n",
            "[train]  epoch 1/1,  batch 731/782,  loss_train=3.25494,  acc_train=23.44%\n",
            "[train]  epoch 1/1,  batch 741/782,  loss_train=3.25844,  acc_train=18.75%\n",
            "[train]  epoch 1/1,  batch 751/782,  loss_train=3.29407,  acc_train=17.19%\n",
            "[train]  epoch 1/1,  batch 761/782,  loss_train=3.34957,  acc_train=20.31%\n",
            "[train]  epoch 1/1,  batch 771/782,  loss_train=3.38658,  acc_train=18.75%\n",
            "[train]  epoch 1/1,  batch 781/782,  loss_train=3.51819,  acc_train=10.94%\n",
            "[ val ]  epoch 1/1,  batch 1/157,  loss_val=3.35715,  acc_val=15.62%\n",
            "[ val ]  epoch 1/1,  batch 11/157,  loss_val=3.38144,  acc_val=18.75%\n",
            "[ val ]  epoch 1/1,  batch 21/157,  loss_val=3.42975,  acc_val=17.19%\n",
            "[ val ]  epoch 1/1,  batch 31/157,  loss_val=3.26253,  acc_val=26.56%\n",
            "[ val ]  epoch 1/1,  batch 41/157,  loss_val=3.44086,  acc_val=17.19%\n",
            "[ val ]  epoch 1/1,  batch 51/157,  loss_val=3.29562,  acc_val=20.31%\n",
            "[ val ]  epoch 1/1,  batch 61/157,  loss_val=3.39753,  acc_val=14.06%\n",
            "[ val ]  epoch 1/1,  batch 71/157,  loss_val=3.21229,  acc_val=18.75%\n",
            "[ val ]  epoch 1/1,  batch 81/157,  loss_val=3.45346,  acc_val=26.56%\n",
            "[ val ]  epoch 1/1,  batch 91/157,  loss_val=3.32155,  acc_val=20.31%\n",
            "[ val ]  epoch 1/1,  batch 101/157,  loss_val=3.18488,  acc_val=14.06%\n",
            "[ val ]  epoch 1/1,  batch 111/157,  loss_val=3.32014,  acc_val=17.19%\n",
            "[ val ]  epoch 1/1,  batch 121/157,  loss_val=3.53382,  acc_val=26.56%\n",
            "[ val ]  epoch 1/1,  batch 131/157,  loss_val=3.07872,  acc_val=25.00%\n",
            "[ val ]  epoch 1/1,  batch 141/157,  loss_val=3.13254,  acc_val=14.06%\n",
            "[ val ]  epoch 1/1,  batch 151/157,  loss_val=3.04100,  acc_val=21.88%\n",
            "==================================================================================Epoch 1/1 summary: loss_train=3.83937, acc_train=11.45%, loss_val=3.25, acc_val=19.22% (best: 19.22% @ epoch 1)==================================================================================\n"
          ]
        }
      ],
      "source": [
        "strmode = f'StanfordDogs_S_TickNet_{NETWORK}_SE'\n",
        "pathout = f'{BASE_DIR}/checkpoints/{strmode}'\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(pathout, exist_ok=True)\n",
        "\n",
        "filenameLOG = pathout + '/' + strmode + '.txt'\n",
        "result_file_path = pathout + '/' + strmode + '.csv'\n",
        "val_accuracy_max = None\n",
        "val_accuracy_argmax = None\n",
        "for n_epoch in range(EPOCH_SIZE):\n",
        "    current_learning_rate = optimizer.param_groups[0]['lr']\n",
        "    print(\n",
        "        f'Starting epoch {n_epoch + 1}/{EPOCH_SIZE}, learning_rate={current_learning_rate}'\n",
        "    )\n",
        "    # train\n",
        "    (train_loss, train_accuracy) = run_epoch(\n",
        "        train=True,\n",
        "        data_loader=train_loader,\n",
        "        model=model,\n",
        "        criterion=criterion,\n",
        "        optimizer=optimizer,\n",
        "        n_epoch=n_epoch,\n",
        "        total_epochs=EPOCH_SIZE,\n",
        "        device=device,\n",
        "    )\n",
        "\n",
        "    # validate\n",
        "    (val_loss, val_accuracy) = run_epoch(\n",
        "        train=False,\n",
        "        data_loader=val_loader,\n",
        "        model=model,\n",
        "        criterion=criterion,\n",
        "        optimizer=None,\n",
        "        n_epoch=n_epoch,\n",
        "        total_epochs=EPOCH_SIZE,\n",
        "        device=device,\n",
        "    )\n",
        "    if (val_accuracy_max is None) or (val_accuracy > val_accuracy_max):\n",
        "      val_accuracy_max = val_accuracy\n",
        "      val_accuracy_argmax = n_epoch\n",
        "      torch.save(\n",
        "          {\"model_state_dict\": model.state_dict()},\n",
        "          f'{pathout}/checkpoint_epoch{n_epoch + 1:>04d}_{100.0 * val_accuracy_max:.2f}.pth',\n",
        "      )\n",
        "\n",
        "    # adjust learning rate\n",
        "    scheduler.step()\n",
        "\n",
        "    # print epoch summary\n",
        "    line = (\n",
        "        '=================================================================================='\n",
        "        f'Epoch {n_epoch + 1}/{EPOCH_SIZE} summary: '\n",
        "        f'loss_train={train_loss:.5f}, '\n",
        "        f'acc_train={100.0 * train_accuracy:.2f}%, '\n",
        "        f'loss_val={val_loss:.2f}, '\n",
        "        f'acc_val={100.0 * val_accuracy:.2f}% '\n",
        "        f'(best: {100.0 * val_accuracy_max:.2f}% @ epoch {(val_accuracy_argmax or 0) + 1})'\n",
        "        '=================================================================================='\n",
        "    )\n",
        "    print(line)\n",
        "    wA.writeLogAcc(filenameLOG, line)\n",
        "    wA.log_results_to_csv(\n",
        "        result_file_path,\n",
        "        n_epoch + 1,\n",
        "        train_loss,\n",
        "        100.0 * train_accuracy,\n",
        "        val_loss,\n",
        "        100.0 * val_accuracy,\n",
        "    )\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "jenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
